# AIé©±åŠ¨æ•°å­¦å¯è§†åŒ–ç³»ç»Ÿä½¿ç”¨æŒ‡å—

## ğŸ“‹ æ¦‚è¿°

æœ¬ç³»ç»Ÿå·²æˆåŠŸä»ä¼ ç»Ÿçš„è§„åˆ™é©±åŠ¨æ¨¡å¼å‡çº§ä¸ºAIé©±åŠ¨æ¨¡å¼ï¼Œæ”¯æŒé€šè¿‡å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è‡ªåŠ¨ç†è§£æ•°å­¦é¢˜ç›®å¹¶ç”Ÿæˆå¯è§†åŒ–ä»£ç ã€‚

## ğŸ—ï¸ ç³»ç»Ÿæ¶æ„

```
ç”¨æˆ·è¾“å…¥é¢˜ç›® â†’ AIåˆ†æç”Ÿæˆä»£ç  â†’ å®‰å…¨éªŒè¯ â†’ æ²™ç®±æ‰§è¡Œ â†’ å›¾ç‰‡ç”Ÿæˆ â†’ è¿”å›ç»“æœ
```

### æ ¸å¿ƒç»„ä»¶

1. **AIæœåŠ¡æ¨¡å—** (`backend/ai_service/`)
   - `llm_client.py`: æ”¯æŒOpenAIã€Claudeã€é€šä¹‰åƒé—®ç­‰å¤šä¸ªLLMæä¾›å•†
   - `prompt_templates.py`: YAMLæ ¼å¼çš„å‚æ•°åŒ–Promptæ¨¡æ¿ç®¡ç†
   - `code_generator.py`: AIä»£ç ç”Ÿæˆå™¨ï¼Œæ”¯æŒé‡è¯•å’Œç½®ä¿¡åº¦è¯„ä¼°

2. **æ‰§è¡Œæ¨¡å—** (`backend/execution/`)
   - `validator.py`: ä»£ç å®‰å…¨éªŒè¯å™¨ï¼Œå¤šå±‚é˜²æŠ¤
   - `executor.py`: æ”¯æŒå—é™æ‰§è¡Œå’Œè¿›ç¨‹æ²™ç®±ä¸¤ç§æ¨¡å¼
   - `sandbox.py`: æ²™ç®±ç®¡ç†å™¨ï¼Œç»Ÿä¸€ç®¡ç†æ‰§è¡Œç¯å¢ƒ

3. **æ•°æ®æ¨¡å‹** (`backend/models/`)
   - `schema.py`: å®Œæ•´çš„æ•°æ®æ¨¡å‹å®šä¹‰ï¼Œæ”¯æŒç±»å‹æ£€æŸ¥

4. **APIæ¥å£** (`backend/api/`)
   - `endpoints.py`: æ–°çš„v2 APIï¼Œå…¼å®¹ä¼ ç»Ÿæ¨¡å¼

5. **Promptæ¨¡æ¿** (`prompts/`)
   - `math_visualization.yaml`: æ”¯æŒå¤šç§å˜ä½“çš„YAMLæ¨¡æ¿

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
# å®‰è£…åŸºç¡€ä¾èµ–
pip install -r requirements-ai.txt

# æ ¹æ®éœ€è¦å®‰è£…LLMå®¢æˆ·ç«¯
pip install openai anthropic  # OpenAIå’ŒClaude
```

### 2. é…ç½®APIå¯†é’¥

```python
# é€šè¿‡APIè®¾ç½®
import requests

# è®¾ç½®OpenAI APIå¯†é’¥
requests.post("http://localhost:8000/api/v2/config/api-key", 
              params={"provider": "openai", "api_key": "your-api-key"})

# è®¾ç½®Claude APIå¯†é’¥  
requests.post("http://localhost:8000/api/v2/config/api-key",
              params={"provider": "claude", "api_key": "your-api-key"})
```

### 3. è¿è¡Œé›†æˆæµ‹è¯•

```bash
python test_ai_system.py
```

### 4. å¯åŠ¨æœåŠ¡

```bash
# æ›´æ–°api_server.pyä»¥åŒ…å«æ–°çš„è·¯ç”±
uvicorn api_server:app --reload --port 8000
```

## ğŸ“ APIä½¿ç”¨æŒ‡å—

### æ–°çš„v2 APIç«¯ç‚¹

#### 1. ç”Ÿæˆå¯è§†åŒ–ï¼ˆæ”¯æŒAIæ¨¡å¼ï¼‰

```python
import requests

# AIæ¨¡å¼è¯·æ±‚
response = requests.post("http://localhost:8000/api/v2/problems/generate", 
                        json={
                            "text": "ç”²ã€ä¹™ä¸¤åœ°ç›¸è·480å…¬é‡Œï¼Œä¸¤è½¦ç›¸å‘è€Œè¡Œï¼Œé€Ÿåº¦åˆ†åˆ«ä¸º60å’Œ80å…¬é‡Œ/å°æ—¶ï¼Œæ±‚ç›¸é‡æ—¶é—´ã€‚",
                            "processing_mode": "ai",
                            "llm_provider": "openai",
                            "prompt_variant": "detailed_mode"
                        })

task_id = response.json()["task_id"]
```

#### 2. æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€

```python
# è½®è¯¢ä»»åŠ¡çŠ¶æ€
import time

while True:
    status_response = requests.get(f"http://localhost:8000/api/v2/tasks/{task_id}")
    status_data = status_response.json()
    
    if status_data["status"] == "completed":
        print("âœ… ä»»åŠ¡å®Œæˆ!")
        print(f"AIåˆ†æ: {status_data['ai_analysis']}")
        print(f"æ‰§è¡Œç»“æœ: {status_data['execution_result']}")
        break
    elif status_data["status"] == "failed":
        print(f"âŒ ä»»åŠ¡å¤±è´¥: {status_data['error_message']}")
        break
    
    print(f"è¿›åº¦: {status_data['progress']}%")
    time.sleep(2)
```

#### 3. å…¼å®¹ä¼ ç»Ÿæ¨¡å¼

```python
# ä¼ ç»Ÿæ¨¡å¼è¯·æ±‚ï¼ˆå‘åå…¼å®¹ï¼‰
response = requests.post("http://localhost:8000/api/v2/problems/generate",
                        json={
                            "text": "ç”²ã€ä¹™ä¸¤åœ°ç›¸è·480å…¬é‡Œï¼Œä¸¤è½¦ç›¸å‘è€Œè¡Œ...",
                            "processing_mode": "traditional"
                        })
```

### ç³»ç»Ÿç®¡ç†API

```python
# è·å–ç³»ç»Ÿç»Ÿè®¡
stats = requests.get("http://localhost:8000/api/v2/stats").json()

# å¥åº·æ£€æŸ¥
health = requests.get("http://localhost:8000/api/v2/health").json()

# æµ‹è¯•LLMè¿æ¥
test_result = requests.post("http://localhost:8000/api/v2/test/connection/openai").json()
```

## ğŸ¨ Promptæ¨¡æ¿è‡ªå®šä¹‰

### åˆ›å»ºæ–°çš„æ¨¡æ¿å˜ä½“

ç¼–è¾‘ `prompts/math_visualization.yaml`:

```yaml
variants:
  my_custom_mode:
    system_prompt: |
      ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•°å­¦å¯è§†åŒ–ä¸“å®¶...
      
    user_prompt_template: |
      é¢˜ç›®ï¼š{problem_text}
      è¾“å‡ºè·¯å¾„ï¼š{output_path}
      
      è¯·ç”Ÿæˆä¸“ä¸šçš„å¯è§†åŒ–ä»£ç ...
```

### ä½¿ç”¨è‡ªå®šä¹‰æ¨¡æ¿

```python
response = requests.post("http://localhost:8000/api/v2/problems/generate",
                        json={
                            "text": "æ•°å­¦é¢˜ç›®...",
                            "processing_mode": "ai", 
                            "prompt_variant": "my_custom_mode"
                        })
```

## ğŸ›¡ï¸ å®‰å…¨é…ç½®

### ä»£ç å®‰å…¨éªŒè¯

ç³»ç»Ÿé»˜è®¤å¼€å¯å¤šå±‚å®‰å…¨éªŒè¯ï¼š

1. **æ¨¡å—å¯¼å…¥é™åˆ¶**: åªå…è®¸matplotlibã€numpyã€mathç­‰å®‰å…¨æ¨¡å—
2. **å‡½æ•°è°ƒç”¨æ£€æŸ¥**: ç¦æ­¢evalã€execã€os.systemç­‰å±é™©å‡½æ•°
3. **æ–‡ä»¶æ“ä½œé™åˆ¶**: é™¤äº†ä¿å­˜å›¾ç‰‡å¤–ç¦æ­¢å…¶ä»–æ–‡ä»¶æ“ä½œ
4. **ç½‘ç»œè®¿é—®é˜»æ–­**: ç¦æ­¢æ‰€æœ‰ç½‘ç»œè¯·æ±‚
5. **èµ„æºä½¿ç”¨é™åˆ¶**: é™åˆ¶å†…å­˜å’ŒCPUä½¿ç”¨

### è‡ªå®šä¹‰å®‰å…¨ç­–ç•¥

```python
from backend.execution.validator import get_security_validator

validator = get_security_validator()

# æ·»åŠ å…è®¸çš„æ¨¡å—
validator.allowed_modules.add('scipy')

# æŸ¥çœ‹å®‰å…¨æŠ¥å‘Š
report = validator.get_security_report()
print(report)
```

## ğŸ“Š ç›‘æ§å’Œè°ƒè¯•

### 1. å®æ—¶ç›‘æ§

```python
# è·å–è¯¦ç»†ç»Ÿè®¡
stats = requests.get("http://localhost:8000/api/v2/stats").json()

print(f"ä»»åŠ¡ç»Ÿè®¡: {stats['task_stats']}")
print(f"AIç”Ÿæˆç»Ÿè®¡: {stats['ai_generation_stats']}")  
print(f"æ²™ç®±ç»Ÿè®¡: {stats['sandbox_stats']}")
```

### 2. æ—¥å¿—è°ƒè¯•

```python
# æŸ¥çœ‹ä»»åŠ¡è¯¦æƒ…
task_detail = requests.get(f"http://localhost:8000/api/v2/tasks/{task_id}").json()

if task_detail["execution_result"]:
    print(f"æ‰§è¡Œæ—¥å¿—: {task_detail['execution_result']['output_logs']}")
    print(f"é”™è¯¯ä¿¡æ¯: {task_detail['execution_result']['error_message']}")
```

### 3. æ€§èƒ½ä¼˜åŒ–

```python
# é…ç½®å¹¶å‘é™åˆ¶
requests.post("http://localhost:8000/api/v2/config", 
              json={"max_concurrent_tasks": 20})

# é€‰æ‹©æ›´å¿«çš„æ‰§è¡Œæ¨¡å¼
requests.post("http://localhost:8000/api/v2/config",
              json={"default_execution_mode": "restricted"})  # æ¯”processæ¨¡å¼æ›´å¿«
```

## ğŸ”§ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **APIå¯†é’¥æœªè®¾ç½®**
   ```
   é”™è¯¯: æœªé…ç½®openaiçš„APIå¯†é’¥
   è§£å†³: é€šè¿‡/api/v2/config/api-keyè®¾ç½®APIå¯†é’¥
   ```

2. **ä»£ç å®‰å…¨éªŒè¯å¤±è´¥**
   ```
   é”™è¯¯: ä»£ç å®‰å…¨éªŒè¯å¤±è´¥: ç¦æ­¢å¯¼å…¥å±é™©æ¨¡å—: os
   è§£å†³: æ£€æŸ¥AIç”Ÿæˆçš„ä»£ç ï¼Œç¡®ä¿åªä½¿ç”¨å…è®¸çš„æ¨¡å—
   ```

3. **æ‰§è¡Œè¶…æ—¶**
   ```
   é”™è¯¯: ä»£ç æ‰§è¡Œè¶…æ—¶
   è§£å†³: ä¼˜åŒ–ç”Ÿæˆçš„ä»£ç æˆ–å¢åŠ timeoutå‚æ•°
   ```

4. **å†…å­˜ä¸è¶³**
   ```
   é”™è¯¯: å†…å­˜ä½¿ç”¨è¶…é™
   è§£å†³: å‡å°‘æ•°æ®è§„æ¨¡æˆ–å¢åŠ å†…å­˜é™åˆ¶
   ```

### è°ƒè¯•æ¨¡å¼

```python
# å¯ç”¨è¯¦ç»†æ—¥å¿—
import logging
logging.basicConfig(level=logging.DEBUG)

# æµ‹è¯•å•ä¸ªç»„ä»¶
from backend.execution.sandbox import get_sandbox_manager
manager = get_sandbox_manager()
result = manager.execute_code_safely(test_code, "output/debug.png")
print(result)
```

## ğŸ“ˆ æ‰©å±•å’Œå®šåˆ¶

### 1. æ·»åŠ æ–°çš„LLMæä¾›å•†

```python
# åœ¨backend/ai_service/llm_client.pyä¸­æ·»åŠ æ–°çš„å®¢æˆ·ç«¯ç±»
class NewLLMClient(BaseLLMClient):
    async def generate_completion(self, system_prompt, user_prompt, config):
        # å®ç°æ–°çš„LLM APIè°ƒç”¨
        pass
```

### 2. è‡ªå®šä¹‰æ²™ç®±æ‰§è¡Œå™¨

```python
# åœ¨backend/execution/executor.pyä¸­æ·»åŠ æ–°çš„æ‰§è¡Œå™¨
class CustomExecutor:
    def execute_code(self, code, output_path, timeout):
        # å®ç°è‡ªå®šä¹‰æ‰§è¡Œé€»è¾‘
        pass
```

### 3. æ‰©å±•æ•°æ®æ¨¡å‹

```python
# åœ¨backend/models/schema.pyä¸­æ·»åŠ æ–°çš„æ¨¡å‹
class CustomRequest(BaseModel):
    # æ·»åŠ æ–°çš„è¯·æ±‚å­—æ®µ
    pass
```

## ğŸ“š å‚è€ƒèµ„æ–™

- [FastAPIæ–‡æ¡£](https://fastapi.tiangolo.com/)
- [Pydanticæ–‡æ¡£](https://docs.pydantic.dev/)
- [OpenAI APIæ–‡æ¡£](https://platform.openai.com/docs)
- [Anthropic Claude APIæ–‡æ¡£](https://docs.anthropic.com/)
- [RestrictedPythonæ–‡æ¡£](https://restrictedpython.readthedocs.io/)

## ğŸ¤ è´¡çŒ®æŒ‡å—

1. è¿è¡Œæµ‹è¯•: `python test_ai_system.py`
2. ä»£ç æ ¼å¼åŒ–: `black backend/`
3. ç±»å‹æ£€æŸ¥: `mypy backend/`
4. æäº¤ä»£ç å‰ç¡®ä¿æ‰€æœ‰æµ‹è¯•é€šè¿‡

---

ğŸ‰ **ç³»ç»Ÿå·²å°±ç»ªï¼** æ‚¨ç°åœ¨å¯ä»¥ä½¿ç”¨AIé©±åŠ¨çš„æ•°å­¦å¯è§†åŒ–åŠŸèƒ½äº†ã€‚
