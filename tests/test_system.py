#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AIæ•°å­¦å¯è§†åŒ–ç³»ç»Ÿç»¼åˆæµ‹è¯•å¥—ä»¶
æ•´åˆäº†å¼€å‘è¿‡ç¨‹ä¸­çš„å„ç§æµ‹è¯•åŠŸèƒ½
"""

import asyncio
import sys
import os
import shutil
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

class SystemTester:
    def __init__(self):
        self.test_output_dir = "tests/output"
        self.ensure_test_dirs()
    
    def ensure_test_dirs(self):
        """ç¡®ä¿æµ‹è¯•ç›®å½•å­˜åœ¨"""
        os.makedirs(self.test_output_dir, exist_ok=True)
    
    def cleanup_test_files(self):
        """æ¸…ç†æµ‹è¯•ç”Ÿæˆçš„æ–‡ä»¶"""
        if os.path.exists(self.test_output_dir):
            shutil.rmtree(self.test_output_dir)
        self.ensure_test_dirs()

    def test_basic_imports(self):
        """æµ‹è¯•åŸºç¡€æ¨¡å—å¯¼å…¥"""
        print("ðŸ§ª æµ‹è¯•åŸºç¡€æ¨¡å—å¯¼å…¥...")
        
        try:
            # æµ‹è¯•æ ¸å¿ƒä¾èµ–
            import matplotlib
            matplotlib.use('Agg')
            import matplotlib.pyplot as plt
            import numpy as np
            print("âœ… æ ¸å¿ƒä¾èµ–åº“å¯¼å…¥æˆåŠŸ")
            
            # æµ‹è¯•é¡¹ç›®æ¨¡å—
            from backend.models.schema import ProblemRequest, LLMProvider
            from backend.ai_service.prompt_templates import render_prompt
            from backend.execution.validator import validate_code_security
            print("âœ… é¡¹ç›®æ¨¡å—å¯¼å…¥æˆåŠŸ")
            
            return True
            
        except Exception as e:
            print(f"âŒ æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
            return False

    def test_pydantic_models(self):
        """æµ‹è¯•Pydanticæ•°æ®æ¨¡åž‹"""
        print("ðŸ§ª æµ‹è¯•Pydanticæ•°æ®æ¨¡åž‹...")
        
        try:
            from backend.models.schema import (
                ProblemRequest, AIAnalysisResult, ExecutionResult, 
                TaskInfo, LLMProvider, PromptTemplate
            )
            
            # æµ‹è¯•ProblemRequest
            request = ProblemRequest(
                problem_text="æµ‹è¯•é—®é¢˜",
                output_filename="test.png",
                llm_provider=LLMProvider.OPENAI
            )
            print(f"âœ… ProblemRequeståˆ›å»ºæˆåŠŸ: {request.problem_text}")
            
            # æµ‹è¯•PromptTemplate
            template = PromptTemplate(
                name="test_template",
                system_prompt="æµ‹è¯•ç³»ç»Ÿæç¤º",
                user_prompt_template="æµ‹è¯•ç”¨æˆ·æç¤º: {problem_text}",
                llm_config={"model": "test-model"}
            )
            print(f"âœ… PromptTemplateåˆ›å»ºæˆåŠŸ: {template.name}")
            
            return True
            
        except Exception as e:
            print(f"âŒ Pydanticæ¨¡åž‹æµ‹è¯•å¤±è´¥: {e}")
            return False

    def test_prompt_system(self):
        """æµ‹è¯•Promptæ¨¡æ¿ç³»ç»Ÿ"""
        print("ðŸ§ª æµ‹è¯•Promptæ¨¡æ¿ç³»ç»Ÿ...")
        
        try:
            from backend.ai_service.prompt_templates import render_prompt, get_prompt_manager
            
            # æµ‹è¯•æ¨¡æ¿æ¸²æŸ“
            system_prompt, user_prompt = render_prompt(
                problem_text="ç”²ã€ä¹™ä¸¤åœ°ç›¸è·480å…¬é‡Œï¼Œä¸¤è½¦ç›¸å‘è€Œè¡Œï¼Œé€Ÿåº¦åˆ†åˆ«ä¸º60å’Œ80å…¬é‡Œ/å°æ—¶ï¼Œæ±‚ç›¸é‡æ—¶é—´ã€‚",
                output_path=f"{self.test_output_dir}/test.png"
            )
            
            # éªŒè¯promptå†…å®¹
            if "æ•°å­¦é¢˜ç›®å¯è§†åŒ–ä¸“å®¶" in system_prompt and "480å…¬é‡Œ" in user_prompt:
                print("âœ… Promptæ¨¡æ¿æ¸²æŸ“æˆåŠŸ")
                print(f"   ç³»ç»ŸPrompt: {len(system_prompt)}å­—ç¬¦")
                print(f"   ç”¨æˆ·Prompt: {len(user_prompt)}å­—ç¬¦")
                return True
            else:
                print("âŒ Promptå†…å®¹éªŒè¯å¤±è´¥")
                return False
                
        except Exception as e:
            print(f"âŒ Promptç³»ç»Ÿæµ‹è¯•å¤±è´¥: {e}")
            return False

    def test_code_validation(self):
        """æµ‹è¯•ä»£ç å®‰å…¨éªŒè¯"""
        print("ðŸ§ª æµ‹è¯•ä»£ç å®‰å…¨éªŒè¯...")
        
        try:
            from backend.execution.validator import validate_code_security
            
            # æµ‹è¯•å®‰å…¨ä»£ç 
            safe_code = """
import matplotlib.pyplot as plt
import numpy as np

x = np.linspace(0, 10, 100)
y = np.sin(x)

plt.figure(figsize=(8, 6))
plt.plot(x, y, 'b-', linewidth=2)
plt.xlabel('X')
plt.ylabel('Y')
plt.title('æµ‹è¯•å›¾è¡¨')
plt.grid(True)
plt.savefig('output/test.png', dpi=300, bbox_inches='tight')
plt.close()

result = {'success': True, 'function': 'sin(x)'}
"""
            
            result = validate_code_security(safe_code)
            if result.is_valid:
                print("âœ… å®‰å…¨ä»£ç éªŒè¯é€šè¿‡")
            else:
                print(f"âŒ å®‰å…¨ä»£ç éªŒè¯å¤±è´¥: {result.security_issues}")
                return False
            
            # æµ‹è¯•å±é™©ä»£ç 
            dangerous_code = "import os; os.system('rm -rf /')"
            result2 = validate_code_security(dangerous_code)
            
            if not result2.is_valid:
                print("âœ… å±é™©ä»£ç è¢«æ­£ç¡®æ‹¦æˆª")
                return True
            else:
                print("âŒ å±é™©ä»£ç æœªè¢«æ‹¦æˆª")
                return False
                
        except Exception as e:
            print(f"âŒ ä»£ç éªŒè¯æµ‹è¯•å¤±è´¥: {e}")
            return False

    def test_code_execution(self):
        """æµ‹è¯•ä»£ç æ‰§è¡ŒåŠŸèƒ½"""
        print("ðŸ§ª æµ‹è¯•ä»£ç æ‰§è¡ŒåŠŸèƒ½...")
        
        try:
            import matplotlib
            matplotlib.use('Agg')
            import matplotlib.pyplot as plt
            import numpy as np
            
            # æµ‹è¯•ä»£ç 
            test_code = f"""
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import numpy as np

plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']

x = np.linspace(0, 10, 50)
y = np.sin(x)

plt.figure(figsize=(8, 6))
plt.plot(x, y, 'b-', linewidth=2, label='sin(x)')
plt.xlabel('X')
plt.ylabel('Y')
plt.title('æµ‹è¯•å›¾è¡¨')
plt.legend()
plt.grid(True, alpha=0.3)

plt.savefig('{self.test_output_dir}/execution_test.png', dpi=300, bbox_inches='tight')
plt.close()

result = {{'success': True, 'function': 'sin(x)'}}
"""
            
            # æ‰§è¡Œä»£ç 
            globals_dict = {}
            exec(test_code, globals_dict)
            
            # æ£€æŸ¥ç»“æžœ
            if os.path.exists(f'{self.test_output_dir}/execution_test.png'):
                print("âœ… ä»£ç æ‰§è¡ŒæˆåŠŸï¼Œå›¾ç‰‡å·²ç”Ÿæˆ")
                return True
            else:
                print("âŒ ä»£ç æ‰§è¡Œå¤±è´¥ï¼Œå›¾ç‰‡æœªç”Ÿæˆ")
                return False
                
        except Exception as e:
            print(f"âŒ ä»£ç æ‰§è¡Œæµ‹è¯•å¤±è´¥: {e}")
            return False

    async def test_llm_clients(self):
        """æµ‹è¯•LLMå®¢æˆ·ç«¯ï¼ˆæ¨¡æ‹Ÿï¼‰"""
        print("ðŸ§ª æµ‹è¯•LLMå®¢æˆ·ç«¯...")
        
        try:
            from backend.ai_service.llm_client import (
                OpenAIClient, ClaudeClient, QwenClient
            )
            
            # æµ‹è¯•å®¢æˆ·ç«¯åˆ›å»ºï¼ˆä¸éœ€è¦çœŸå®žAPIå¯†é’¥ï¼‰
            openai_client = OpenAIClient()
            claude_client = ClaudeClient()
            qwen_client = QwenClient()
            
            print("âœ… LLMå®¢æˆ·ç«¯åˆ›å»ºæˆåŠŸ")
            print(f"   OpenAIå®¢æˆ·ç«¯: {type(openai_client).__name__}")
            print(f"   Claudeå®¢æˆ·ç«¯: {type(claude_client).__name__}")
            print(f"   Qwenå®¢æˆ·ç«¯: {type(qwen_client).__name__}")
            
            return True
            
        except Exception as e:
            print(f"âŒ LLMå®¢æˆ·ç«¯æµ‹è¯•å¤±è´¥: {e}")
            return False

    def test_api_endpoints(self):
        """æµ‹è¯•APIç«¯ç‚¹ï¼ˆæ¨¡æ‹Ÿï¼‰"""
        print("ðŸ§ª æµ‹è¯•APIç«¯ç‚¹...")
        
        try:
            from backend.api.endpoints import app
            print("âœ… FastAPIåº”ç”¨åˆ›å»ºæˆåŠŸ")
            
            # æ£€æŸ¥è·¯ç”±
            routes = [route.path for route in app.routes]
            expected_routes = ["/api/v2/problems/generate", "/api/v2/tasks/"]
            
            for route in expected_routes:
                if any(route in r for r in routes):
                    print(f"âœ… è·¯ç”±å­˜åœ¨: {route}")
                else:
                    print(f"âŒ è·¯ç”±ç¼ºå¤±: {route}")
                    return False
            
            return True
            
        except Exception as e:
            print(f"âŒ APIç«¯ç‚¹æµ‹è¯•å¤±è´¥: {e}")
            return False

    async def run_all_tests(self):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        print("ðŸš€ å¼€å§‹è¿è¡Œç³»ç»Ÿç»¼åˆæµ‹è¯•\n")
        print("="*60)
        
        tests = [
            ("åŸºç¡€æ¨¡å—å¯¼å…¥", self.test_basic_imports),
            ("Pydanticæ•°æ®æ¨¡åž‹", self.test_pydantic_models),
            ("Promptæ¨¡æ¿ç³»ç»Ÿ", self.test_prompt_system),
            ("ä»£ç å®‰å…¨éªŒè¯", self.test_code_validation),
            ("ä»£ç æ‰§è¡ŒåŠŸèƒ½", self.test_code_execution),
            ("LLMå®¢æˆ·ç«¯", self.test_llm_clients),
            ("APIç«¯ç‚¹", self.test_api_endpoints)
        ]
        
        results = []
        for test_name, test_func in tests:
            print(f"\nðŸ“‹ {test_name}:")
            print("-" * 40)
            
            if asyncio.iscoroutinefunction(test_func):
                result = await test_func()
            else:
                result = test_func()
                
            results.append((test_name, result))
        
        # æ±‡æ€»ç»“æžœ
        print("\n" + "="*60)
        print("æµ‹è¯•ç»“æžœæ±‡æ€»:")
        print("="*60)
        
        passed = 0
        for test_name, result in results:
            status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
            print(f"{test_name:20} {status}")
            if result:
                passed += 1
        
        total = len(results)
        success_rate = passed / total
        
        print("-" * 60)
        print(f"æ€»è®¡: {passed}/{total} é€šè¿‡")
        print(f"æˆåŠŸçŽ‡: {success_rate:.1%}")
        
        if success_rate == 1.0:
            print("\nðŸŽ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ç³»ç»ŸçŠ¶æ€è‰¯å¥½")
        elif success_rate >= 0.8:
            print("\nâœ… å¤§éƒ¨åˆ†æµ‹è¯•é€šè¿‡ï¼Œç³»ç»ŸåŸºæœ¬å¯ç”¨")
        elif success_rate >= 0.6:
            print("\nâš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦æ£€æŸ¥")
        else:
            print("\nâŒ å¤šä¸ªæµ‹è¯•å¤±è´¥ï¼Œç³»ç»Ÿéœ€è¦ä¿®å¤")
        
        return success_rate

    def cleanup_and_summary(self):
        """æ¸…ç†å¹¶æ€»ç»“"""
        print(f"\nðŸ§¹ æ¸…ç†æµ‹è¯•æ–‡ä»¶...")
        
        # å¯é€‰æ‹©æ€§ä¿ç•™ä¸€äº›æœ‰ç”¨çš„æµ‹è¯•è¾“å‡º
        test_files = []
        if os.path.exists(f'{self.test_output_dir}/execution_test.png'):
            test_files.append('execution_test.png')
        
        if test_files:
            print(f"âœ… ä¿ç•™æµ‹è¯•æ–‡ä»¶: {', '.join(test_files)}")
        
        print("âœ… æµ‹è¯•å®Œæˆ")


def main():
    """ä¸»å‡½æ•°"""
    tester = SystemTester()
    
    try:
        # è¿è¡Œå¼‚æ­¥æµ‹è¯•
        result = asyncio.run(tester.run_all_tests())
        
        # æ¸…ç†å’Œæ€»ç»“
        tester.cleanup_and_summary()
        
        return result
        
    except KeyboardInterrupt:
        print("\nâš ï¸ æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
        return 0.0
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•æ‰§è¡Œå¤±è´¥: {e}")
        return 0.0


if __name__ == "__main__":
    success_rate = main()
    exit_code = 0 if success_rate >= 0.8 else 1
    sys.exit(exit_code)
